import datetime
import json
import os
import re
import time

import pandas as pd
import requests
import streamlit as st
from langchain.agents import tool, initialize_agent
from langchain.agents.agent_types import AgentType
from langchain.chains import LLMRequestsChain, LLMChain
from langchain.prompts import PromptTemplate
from langchain_community.llms import Tongyi

import utils
from config import Config


def qa_page():
    # Streamlit åº”ç”¨
    st.title("ğŸ’¬ çŸ¥è¯†é—®ç­”")

    os.environ["DASHSCOPE_API_KEY"] = Config.dashscope_api_key
    os.environ["AMAP_TOKEN"] = Config.amap_token
    llm = Tongyi(model_name="qwen-max")

    ORDER_1 = "20230611ABC"
    ORDER_2 = "20230611EFG"

    ORDER_1_DETAIL = {
        "order_number": ORDER_1,
        "status": "å·²å‘è´§",
        "shipping_date": "2023-01-03",
        "estimated_delivered_date": "2023-01-05",
    }

    ORDER_2_DETAIL = {
        "order_number": ORDER_2,
        "status": "æœªå‘è´§",
        "shipping_date": None,
        "estimated_delivered_date": None,
    }

    @tool("Search Order")
    def search_order(input: str) -> str:
        """ä¸€ä¸ªå¸®åŠ©ç”¨æˆ·æŸ¥è¯¢æœ€æ–°è®¢å•çŠ¶æ€çš„å·¥å…·ï¼Œå¹¶ä¸”èƒ½å¤„ç†ä»¥ä¸‹æƒ…å†µï¼š
        1. åœ¨ç”¨æˆ·æ²¡æœ‰è¾“å…¥è®¢å•å·çš„æ—¶å€™ï¼Œä¼šè¯¢é—®ç”¨æˆ·è®¢å•å·
        2. åœ¨ç”¨æˆ·è¾“å…¥çš„è®¢å•å·æŸ¥è¯¢ä¸åˆ°çš„æ—¶å€™ï¼Œä¼šè®©ç”¨æˆ·äºŒæ¬¡ç¡®è®¤è®¢å•å·æ˜¯å¦æ­£ç¡®
        """
        pattern = r"\d+[A-Z]+"
        match = re.search(pattern, input)

        order_number = input
        if match:
            order_number = match.group(0)
        else:
            return "è¯·é—®æ‚¨çš„è®¢å•å·æ˜¯å¤šå°‘ï¼Ÿ"
        if order_number == ORDER_1:
            return json.dumps(ORDER_1_DETAIL)
        elif order_number == ORDER_2:
            return json.dumps(ORDER_2_DETAIL)
        else:
            return f"å¯¹ä¸èµ·ï¼Œæ ¹æ®{input}æ²¡æœ‰æ‰¾åˆ°æ‚¨çš„è®¢å•"

    @tool("get_baike", return_direct=True)
    def get_baike(query: str) -> str:
        """ä½ æ˜¯Googleå°åŠ©æ‰‹ï¼Œå¯ä»¥æŸ¥è¯¢ä»»ä½•äººç‰©ï¼Œäº‹ä»¶ï¼Œç‰©å“çš„ç™¾ç§‘ä¿¡æ¯ã€‚
        """
        # å®šä¹‰ä»è°·æ­Œç½‘é¡µä¸­æœç´¢å‡ºæƒ³è¦ä¿¡æ¯çš„æ¨¡ç‰ˆ
        template = """åœ¨ >>> å’Œ <<< ç›´æ¥æ˜¯æ¥è‡ªGoogleçš„åŸå§‹æœç´¢ç»“æœ.
                   è¯·æŠŠå¯¹äºé—®é¢˜ '{query}' çš„ç­”æ¡ˆä»é‡Œé¢æå–å‡ºæ¥ï¼Œå¦‚æœé‡Œé¢æ²¡æœ‰ç›¸å…³ä¿¡æ¯çš„è¯å°±è¯´ "æ‰¾ä¸åˆ°"
                   è¯·ä½¿ç”¨å¦‚ä¸‹æ ¼å¼ï¼š
                   Extracted:<answer or "æ‰¾ä¸åˆ°">
                   >>> {requests_result} <<<
                   Extracted:
                   """
        PROMPT = PromptTemplate(
            input_variables=["query", "requests_result"],
            template=template,
        )
        # å°†æŠŠPROMPTä¼ ç»™LLMRequestsChain
        request_chain = LLMRequestsChain(llm_chain=LLMChain(llm=llm, prompt=PROMPT))
        # å¯¹åº”çš„æœç´¢è¯è¯­ï¼Œé€šè¿‡queryå‚æ•°ä¼ å…¥ï¼Œå¯¹åº”çš„åŸå§‹æœç´¢ç»“æœé»˜è®¤æ”¾å…¥requests_resultï¼Œæœ‰å¯¹åº”çš„å ä½ç¬¦æ›¿æ¢
        question = query
        inputs = {
            "query": question,
            "url": "https://www.google.com/search?q=" + question.replace(" ", "+")
        }
        # è¿è¡Œä¸€ä¸‹å°±ä¼šé€šè¿‡OpeenAIæå–æœç´¢ç»“æœ
        result = request_chain(inputs)
        print("\n")
        print(result)
        return result['output']

    @tool("get_product", return_direct=True)
    def get_product(query: str) -> str:
        """ä»æ˜“å® å•†åŸä¸­æ¨èå® ç‰©ç”¨å“ï¼Œé£Ÿå“ï¼Œè¯å“
        1.è¿”å›ä¿¡æ¯ä¸€è¡Œä¸€æ¡ï¼Œæ ¼å¼å¯¹é½ï¼Œè¦æ±‚æœ‰å•†å“æ ‡é¢˜ï¼Œä»·æ ¼ï¼Œæ˜¯å¦æœ‰è´§
        """
        # å®šä¹‰ä»è°·æ­Œç½‘é¡µä¸­æœç´¢å‡ºæƒ³è¦ä¿¡æ¯çš„æ¨¡ç‰ˆ
        template = """åœ¨ >>> å’Œ <<< ç›´æ¥æ˜¯æ¥è‡ªæ˜“å® å•†åŸçš„åŸå§‹æœç´¢ç»“æœ.
                   è¯·æŠŠå¯¹äºé—®é¢˜ '{query}' çš„ç­”æ¡ˆä»é‡Œé¢æå–å‡ºæ¥ï¼Œå¦‚æœé‡Œé¢æ²¡æœ‰ç›¸å…³ä¿¡æ¯çš„è¯å°±è¯´ "æ‰¾ä¸åˆ°"
                   è¿”å›æ•°æ®çš„æ ¼å¼å¯¹é½å¦‚ä¸‹ï¼šè¦æ±‚æœ‰å•†å“æ ‡é¢˜ï¼Œä»·æ ¼ï¼Œæ˜¯å¦æœ‰è´§ ç©ºä¸€è¡Œ,markdownæ ¼å¼
                   è¯·ä½¿ç”¨å¦‚ä¸‹æ ¼å¼ï¼š
                   Extracted:
                   <answer or "æ‰¾ä¸åˆ°">
                   >>> {requests_result} <<<
                   Extracted:
                   """
        PROMPT = PromptTemplate(
            input_variables=["query", "requests_result"],
            template=template,
        )
        # å°†æŠŠPROMPTä¼ ç»™LLMRequestsChain
        request_chain = LLMRequestsChain(llm_chain=LLMChain(llm=llm, prompt=PROMPT))
        # å¯¹åº”çš„æœç´¢è¯è¯­ï¼Œé€šè¿‡queryå‚æ•°ä¼ å…¥ï¼Œå¯¹åº”çš„åŸå§‹æœç´¢ç»“æœé»˜è®¤æ”¾å…¥requests_resultï¼Œæœ‰å¯¹åº”çš„å ä½ç¬¦æ›¿æ¢
        question = query
        inputs = {
            "query": question,
            "url": "https://list.epet.com/search/main.html?keyword={0}&version=2.0.0&attrid=".format(
                question.replace(" ", "+"))
        }
        # è¿è¡Œä¸€ä¸‹å°±ä¼šé€šè¿‡OpeenAIæå–æœç´¢ç»“æœ
        result = request_chain(inputs)
        print("\n")
        print(result)
        return result['output']

    @tool("get_time")
    def get_time(intput: str) -> str:
        """è·å–æ—¶é—´,è¦è½¬åŒ–ä¸ºäººçœ¼èƒ½å¤Ÿ ä¸€çœ¼å°±è¯†åˆ«çš„æ ¼å¼ Y-m-d H:i:s
        1.å¦‚æœè¦è·å–å…¶ä»–æ—¶é—´ï¼Œå¯ä»¥å…ˆè·å–ä»Šå¤©çš„æ—¶é—´ï¼Œå†å»æ¨ç®—
        2.æœªæ¥çš„æŸä¸ªæ—¶é—´ä¹Ÿæ ¹æ®ä»Šå¤©çš„æ—¶é—´å»æ¨ç®—
        """
        now = datetime.datetime.now()
        formatted_time = now.strftime("%Y-%m-%d %H:%M:%S")
        return formatted_time

    @tool("get_amap_weather")
    def get_amap_weather(intput: str):
        """
        æŸ¥è¯¢åŸå¸‚å¤©æ°”é¢„æŠ¥
        """
        city_df = pd.read_excel(
            'https://modelscope.oss-cn-beijing.aliyuncs.com/resource/agent/AMap_adcode_citycode.xlsx'
        )
        token = Config.amap_token
        if token is None:
            return "è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®AMAP_TOKEN"

        def get_city_adcode(city_df, city_name):
            filtered_df = city_df[city_df['ä¸­æ–‡å'].str.contains(city_name, na=False)]
            if len(filtered_df['adcode'].values) == 0:
                raise ValueError(
                    f'location {city_name} not found, availables are {city_df["ä¸­æ–‡å"]}'
                )
            else:
                return filtered_df['adcode'].values[0]

        adcode = get_city_adcode(city_df, intput)
        url = 'https://restapi.amap.com/v3/weather/weatherInfo?city={city}&key={key}'
        full_url = url.format(city=adcode, key=token)

        response = requests.get(full_url)
        data = response.json()

        if data['status'] == '0':
            raise RuntimeError(data)
        else:
            weather = data['lives'][0]['weather']
            temperature = data['lives'][0]['temperature']
            return {'result': f'{intput}çš„å¤©æ°”æ˜¯{weather}æ¸©åº¦æ˜¯{temperature}åº¦ã€‚'}

    @tool("get_faq")
    def get_faq(query: str):
        """
        ä¼˜å…ˆé€šè¿‡æœ¬åœ°çŸ¥è¯†åº“é—®ç­”,å°ç±³æ±½è½¦(su7)ç­”ç½‘å‹100é—®,åŠ³åŠ¨æ³•å­¦ä¹ å®æ“æ‰‹å†Œã€‚å¦‚æœæœ¬åœ°çŸ¥è¯†åº“å›ç­”ä¸äº†ï¼Œå†é€šè¿‡get_baikeè¿›å»å›ç­”
        """
        embeddings = utils.load_embeddings()
        db = utils.load_chroma_db(embeddings)
        page_content = utils.load_similarity_search(db, query)
        if page_content == "":
            return "å¯¹ä¸èµ·ï¼Œæˆ‘ä¸çŸ¥é“è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€‚è¯·å…ˆä¸Šä¼ ç›¸å…³çš„çŸ¥è¯†åº“æ–‡æ¡£æ–‡ä»¶"

        response = utils.qwen_chat(query, page_content)
        return response

    # ç”¨æˆ·è¾“å…¥é—®é¢˜
    question_input = st.text_input(label="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:", placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")

    # å½“ç”¨æˆ·ç‚¹å‡»æŒ‰é’®æ—¶æ‰§è¡Œ
    if st.button("æé—®"):
        if question_input == "":
            warning_tips = st.warning("è¯·è¾“å…¥æ‚¨çš„æé—®")
            time.sleep(2)
            warning_tips.empty()
            return
        info_tips = st.info("æ­£åœ¨ä¸ºæ‚¨å›ç­”é—®é¢˜...")

        tools = [
            get_baike,
            get_product,
            search_order,
            get_amap_weather,
            get_time,
            get_faq
        ]

        agent = initialize_agent(
            tools,
            llm,
            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            verbose=True
        )

        answer = agent.run(question_input)

        # prompt_template = "è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚æé—®{é—®é¢˜}"
        # qa = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))
        # answer = qa(question_input)

        info_tips.empty()
        info_tips.info("ä»¥ä¸‹æ˜¯ç»™å‡ºçš„ç­”æ¡ˆ")
        # æ˜¾ç¤ºç»“æœ
        if answer == "ã€‚":
            st.warning("å¯¹ä¸èµ·ï¼Œæˆ‘ä¸çŸ¥é“è¿™ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€‚")
        else:
            st.write(f"é—®é¢˜: {question_input}")
            st.write(f"ç­”æ¡ˆ: {answer}")
